version: '3.8'

services:
  # ===========================
  #       PROMETHEUS
  # ===========================

  prometheus:
    image: prom/prometheus:v2.47.2
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus_v2.yml:/etc/prometheus/prometheus.yml
    networks:
      - cluster-net
    restart: always
    shm_size: '2gb'

  # ===========================
  #       GRAFANA
  # ===========================
  grafana:
    image: grafana/grafana:9.4.3
    container_name: grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - cluster-net
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2g
    shm_size: '2gb'
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false

  # ===========================
  #       SPARK SERVICES
  # ===========================
  spark-master:
    image: mi-spark-py39
    container_name: spark-master
    command: >
      bash -c "
        export JMX_PORT=9990 &&
        source /configs/setup_prometheus.sh &&
        exec /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master --host spark-master
      "
    ports:
      - "7077:7077"
      - "8080:8080"
      - "4040:4040" 
    networks:
      - cluster-net
    volumes:
      - ./data:/data
      - ./scripts:/scripts
      - ./helpers:/helpers
      - ./benchmarks:/benchmarks
      - ./EDA:/EDA
      - ./pipelines:/pipelines
      - ./logs:/logs
      - ./configs:/configs
    environment:
      - SPARK_CONF_DIR=/configs
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 4g
    shm_size: '2gb'

  spark-worker-1:
    image: mi-spark-py39
    container_name: spark-worker-1
    command: >
      bash -c "
        export JMX_PORT=9991 &&
        source /configs/setup_prometheus.sh &&
        exec /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
      "
    depends_on:
      - spark-master
    networks:
      - cluster-net
    ports: []
    volumes:
      - ./data:/data
      - ./scripts:/scripts
      - ./helpers:/helpers
      - ./benchmarks:/benchmarks
      - ./EDA:/EDA
      - ./pipelines:/pipelines
      - ./logs:/logs
      - ./configs:/configs
    environment:
      - SPARK_CONF_DIR=/configs
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 10g
    shm_size: '2gb'

  spark-worker-2:
    image: mi-spark-py39
    container_name: spark-worker-2
    command: >
      bash -c "
        export JMX_PORT=9992 &&
        source /configs/setup_prometheus.sh &&
        exec /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
      "
    depends_on:
      - spark-master
    networks:
      - cluster-net
    ports: 
      - "8081:8081"
    volumes:
      - ./data:/data
      - ./scripts:/scripts
      - ./helpers:/helpers
      - ./benchmarks:/benchmarks
      - ./EDA:/EDA
      - ./pipelines:/pipelines
      - ./logs:/logs
      - ./configs:/configs
    environment:
      - SPARK_CONF_DIR=/configs
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 10g
    shm_size: '2gb'

  spark-worker-3:
    image: mi-spark-py39
    container_name: spark-worker-3
    command: >
      bash -c "
        export JMX_PORT=9993 &&
        source /configs/setup_prometheus.sh &&
        exec /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
      "
    depends_on:
      - spark-master
    networks:
      - cluster-net
    ports: 
      - "8082:8082"
    volumes:
      - ./data:/data
      - ./scripts:/scripts
      - ./helpers:/helpers
      - ./benchmarks:/benchmarks
      - ./EDA:/EDA
      - ./pipelines:/pipelines
      - ./logs:/logs
      - ./configs:/configs
    environment:
      - SPARK_CONF_DIR=/configs
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 10g
    shm_size: '2gb'

  spark-worker-4:
    image: mi-spark-py39
    container_name: spark-worker-4
    command: >
      bash -c "
        export JMX_PORT=9994 &&
        source /configs/setup_prometheus.sh &&
        exec /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
      "
    depends_on:
      - spark-master
    networks:
      - cluster-net
    ports: 
      - "8083:8083"
    volumes:
      - ./data:/data
      - ./scripts:/scripts
      - ./helpers:/helpers
      - ./benchmarks:/benchmarks
      - ./EDA:/EDA
      - ./pipelines:/pipelines
      - ./logs:/logs
      - ./configs:/configs
    environment:
      - SPARK_CONF_DIR=/configs
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 10g
    shm_size: '2gb'

  spark-worker-5:
    image: mi-spark-py39
    container_name: spark-worker-5
    command: >
      bash -c "
        export JMX_PORT=9995 &&
        source /configs/setup_prometheus.sh &&
        exec /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
      "
    depends_on:
      - spark-master
    networks:
      - cluster-net
    ports: 
      - "8084:8084"
    volumes:
      - ./data:/data
      - ./scripts:/scripts
      - ./helpers:/helpers
      - ./benchmarks:/benchmarks
      - ./EDA:/EDA
      - ./pipelines:/pipelines
      - ./logs:/logs
      - ./configs:/configs
    environment:
      - SPARK_CONF_DIR=/configs
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 10g
    shm_size: '2gb'

networks:
  cluster-net:
    driver: bridge

volumes:
  grafana_data: