version: '3.8'

services:
# ===========================
#       SPARK SERVICES
# ===========================
  spark-master:
    image: mi-spark-py39
    container_name: spark-master
    command: >
      bash -c "
        export JMX_PORT=9990 &&
        exec /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master --host spark-master
      "
    ports:
      - "7077:7077"
      - "8080:8080"
      - "4040:4040" 
    networks:
      - cluster-net
    volumes:
      - ./data:/data
      - ./scripts:/scripts
      - ./helpers:/helpers
      - ./logs:/logs
      - ./configs:/configs
    environment:
      - SPARK_CONF_DIR=/configs
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4g
    shm_size: '2gb'

  spark-worker-1:
    image: mi-spark-py39
    container_name: spark-worker-1
    command: >
      bash -c "
        export JMX_PORT=9991 &&
        exec /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
      "
    depends_on:
      - spark-master
    networks:
      - cluster-net
    ports: []
    volumes:
      - ./data:/data
      - ./scripts:/scripts
      - ./helpers:/helpers
      - ./logs:/logs
      - ./configs:/configs
    environment:
      - SPARK_CONF_DIR=/configs
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 10g
    shm_size: '2gb'

  spark-worker-2:
    image: mi-spark-py39
    container_name: spark-worker-2
    command: >
      bash -c "
        export JMX_PORT=9992 &&
        exec /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
      "
    depends_on:
      - spark-master
    networks:
      - cluster-net
    ports: 
      - "8081:8081"
    volumes:
      - ./data:/data
      - ./scripts:/scripts
      - ./helpers:/helpers
      - ./logs:/logs
      - ./configs:/configs
    environment:
      - SPARK_CONF_DIR=/configs
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 10g
    shm_size: '2gb'

  spark-worker-3:
    image: mi-spark-py39
    container_name: spark-worker-3
    command: >
      bash -c "
        export JMX_PORT=9993 &&
        exec /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
      "
    depends_on:
      - spark-master
    networks:
      - cluster-net
    ports: 
      - "8082:8082"
    volumes:
      - ./data:/data
      - ./scripts:/scripts
      - ./helpers:/helpers
      - ./logs:/logs
      - ./configs:/configs
    environment:
      - SPARK_CONF_DIR=/configs
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 10g
    shm_size: '2gb'

  spark-worker-4:
    image: mi-spark-py39
    container_name: spark-worker-4
    command: >
      bash -c "
        export JMX_PORT=9994 &&
        exec /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
      "
    depends_on:
      - spark-master
    networks:
      - cluster-net
    ports: 
      - "8083:8083"
    volumes:
      - ./data:/data
      - ./scripts:/scripts
      - ./helpers:/helpers
      - ./logs:/logs
      - ./configs:/configs
    environment:
      - SPARK_CONF_DIR=/configs
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 10g
    shm_size: '2gb'

  spark-worker-5:
    image: mi-spark-py39
    container_name: spark-worker-5
    command: >
      bash -c "
        export JMX_PORT=9995 &&
        exec /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
      "
    depends_on:
      - spark-master
    networks:
      - cluster-net
    ports: 
      - "8084:8084"
    volumes:
      - ./data:/data
      - ./scripts:/scripts
      - ./helpers:/helpers
      - ./logs:/logs
      - ./configs:/configs
    environment:
      - SPARK_CONF_DIR=/configs
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 10g
    shm_size: '2gb'

networks:
  cluster-net:
    driver: bridge
